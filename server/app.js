// ============= server/app.js (CORSä¿®å¤ç‰ˆ) =============
const express = require("express");
const cors = require("cors");
const axios = require("axios");
const { HttpsProxyAgent } = require("https-proxy-agent");
require("dotenv").config();

const app = express();
const PORT = process.env.PORT || 3001;

// ä¿®å¤CORSé…ç½®
app.use(
  cors({
    origin: [
      "http://localhost:3000",
      "http://127.0.0.1:3000",
      "http://localhost:5173",
      "http://127.0.0.1:5173",
      process.env.FRONTEND_URL,
    ].filter(Boolean),
    credentials: true,
    methods: ["GET", "POST", "PUT", "DELETE", "OPTIONS"],
    allowedHeaders: ["Content-Type", "Authorization", "X-Requested-With"],
  })
);

// å¤„ç†é¢„æ£€è¯·æ±‚
app.options("*", cors());

app.use(express.json({ limit: "10mb" }));
app.use(express.urlencoded({ extended: true }));

// ä»£ç†é…ç½®
const PROXY_URL = process.env.PROXY_URL;
const agent = PROXY_URL ? new HttpsProxyAgent(PROXY_URL) : undefined;

// å¢å¼ºçš„æ—¥å¿—ä¸­é—´ä»¶
app.use((req, res, next) => {
  const timestamp = new Date().toISOString();
  console.log(
    `[${timestamp}] ${req.method} ${req.path} - Origin: ${
      req.get("Origin") || "none"
    }`
  );
  next();
});

// AIæœåŠ¡é…ç½®
const AI_SERVICES = {
  openai: {
    baseURL: process.env.OPENAI_BASE_URL || "https://api.openai.com/v1",
    defaultModel: "gpt-3.5-turbo",
  },
  anthropic: {
    baseURL: process.env.ANTHROPIC_BASE_URL || "https://api.anthropic.com",
    defaultModel: "claude-3-sonnet",
  },
  zhipu: {
    baseURL:
      process.env.ZHIPU_BASE_URL || "https://open.bigmodel.cn/api/paas/v4",
    defaultModel: "glm-4",
  },
  qwen: {
    baseURL:
      process.env.QWEN_BASE_URL || "https://dashscope.aliyuncs.com/api/v1",
    defaultModel: "qwen-turbo",
  },
  gemini: {
    baseURL:
      process.env.GEMINI_BASE_URL ||
      "https://generativelanguage.googleapis.com/v1beta",
    defaultModel: "gemini-pro",
  },
};

// åˆ›å»ºaxioså®ä¾‹çš„å·¥å‚å‡½æ•°
const createAxiosInstance = (baseURL, headers = {}) => {
  const config = {
    baseURL,
    timeout: 30000,
    headers: {
      "Content-Type": "application/json",
      ...headers,
    },
  };

  if (agent) {
    config.httpsAgent = agent;
    config.httpAgent = agent;
    console.log(`ä½¿ç”¨ä»£ç†: ${PROXY_URL}`);
  }

  return axios.create(config);
};

// ============= å¥åº·æ£€æŸ¥ (å¢å¼ºç‰ˆ) =============
app.get("/api/health", (req, res) => {
  console.log("æ”¶åˆ°å¥åº·æ£€æŸ¥è¯·æ±‚");

  const healthData = {
    status: "ok",
    timestamp: new Date().toISOString(),
    server: {
      port: PORT,
      nodeVersion: process.version,
      uptime: process.uptime(),
    },
    proxy: PROXY_URL ? "enabled" : "disabled",
    services: Object.keys(AI_SERVICES),
    cors: {
      origin: req.get("Origin") || "none",
      method: req.method,
    },
  };

  if (PROXY_URL) {
    healthData.proxyUrl = PROXY_URL;
  }

  console.log("è¿”å›å¥åº·æ£€æŸ¥æ•°æ®:", healthData);
  res.json(healthData);
});

// ç®€å•çš„æ ¹è·¯å¾„å“åº”
app.get("/", (req, res) => {
  res.json({
    message: "AI Chat Backend Server",
    version: "1.0.0",
    endpoints: [
      "/api/health",
      "/api/openai/chat",
      "/api/zhipu/chat",
      "/api/anthropic/chat",
      "/api/qwen/chat",
      "/api/gemini/chat",
      "/api/test",
    ],
  });
});

// ============= OpenAI APIå¤„ç† =============
app.post("/api/openai/chat", async (req, res) => {
  console.log("æ”¶åˆ°OpenAIèŠå¤©è¯·æ±‚");

  try {
    const { messages, model, stream = true, apiKey, ...otherParams } = req.body;

    if (!apiKey) {
      console.log("APIå¯†é’¥ç¼ºå¤±");
      return res.status(400).json({ error: "APIå¯†é’¥æœªæä¾›" });
    }

    const axiosInstance = createAxiosInstance(AI_SERVICES.openai.baseURL, {
      Authorization: `Bearer ${apiKey}`,
    });

    const payload = {
      model: model || AI_SERVICES.openai.defaultModel,
      messages,
      stream,
      temperature: 0.7,
      max_tokens: 2000,
      ...otherParams,
    };

    console.log(
      `å‘é€è¯·æ±‚åˆ°OpenAI: ${AI_SERVICES.openai.baseURL}/chat/completions`
    );

    if (stream) {
      const response = await axiosInstance.post("/chat/completions", payload, {
        responseType: "stream",
      });

      res.setHeader("Content-Type", "text/event-stream");
      res.setHeader("Cache-Control", "no-cache");
      res.setHeader("Connection", "keep-alive");
      res.setHeader("Access-Control-Allow-Origin", "*");

      response.data.on("data", (chunk) => {
        res.write(chunk);
      });

      response.data.on("end", () => {
        console.log("OpenAIæµå¼å“åº”å®Œæˆ");
        res.end();
      });

      response.data.on("error", (error) => {
        console.error("OpenAIæµå¼å“åº”é”™è¯¯:", error);
        if (!res.headersSent) {
          res.status(500).json({ error: "æµå¼å“åº”é”™è¯¯" });
        }
      });
    } else {
      const response = await axiosInstance.post("/chat/completions", payload);
      console.log("OpenAIéæµå¼å“åº”æˆåŠŸ");
      res.json(response.data);
    }
  } catch (error) {
    console.error("OpenAI APIé”™è¯¯:", error.response?.data || error.message);
    if (!res.headersSent) {
      res.status(error.response?.status || 500).json({
        error:
          error.response?.data?.error?.message ||
          error.message ||
          "OpenAI APIè°ƒç”¨å¤±è´¥",
      });
    }
  }
});

// ============= æ™ºè°±AIå¤„ç† =============
app.post("/api/zhipu/chat", async (req, res) => {
  console.log("æ”¶åˆ°æ™ºè°±AIèŠå¤©è¯·æ±‚");

  try {
    const { messages, model, stream = true, apiKey, ...otherParams } = req.body;

    if (!apiKey) {
      return res.status(400).json({ error: "APIå¯†é’¥æœªæä¾›" });
    }

    const axiosInstance = createAxiosInstance(AI_SERVICES.zhipu.baseURL, {
      Authorization: `Bearer ${apiKey}`,
    });

    const payload = {
      model: model || AI_SERVICES.zhipu.defaultModel,
      messages,
      stream,
      temperature: 0.7,
      max_tokens: 2000,
      ...otherParams,
    };

    if (stream) {
      const response = await axiosInstance.post("/chat/completions", payload, {
        responseType: "stream",
      });

      res.setHeader("Content-Type", "text/event-stream");
      res.setHeader("Cache-Control", "no-cache");
      res.setHeader("Connection", "keep-alive");
      res.setHeader("Access-Control-Allow-Origin", "*");

      response.data.pipe(res);
    } else {
      const response = await axiosInstance.post("/chat/completions", payload);
      res.json(response.data);
    }
  } catch (error) {
    console.error("æ™ºè°±AIé”™è¯¯:", error.response?.data || error.message);
    if (!res.headersSent) {
      res.status(error.response?.status || 500).json({
        error:
          error.response?.data?.error?.message ||
          error.message ||
          "æ™ºè°±AIè°ƒç”¨å¤±è´¥",
      });
    }
  }
});

// ============= Anthropic Claudeå¤„ç† =============
app.post("/api/anthropic/chat", async (req, res) => {
  try {
    const { messages, model, stream = true, apiKey, ...otherParams } = req.body;

    if (!apiKey) {
      return res.status(400).json({ error: "APIå¯†é’¥æœªæä¾›" });
    }

    const axiosInstance = createAxiosInstance(AI_SERVICES.anthropic.baseURL, {
      "x-api-key": apiKey,
      "anthropic-version": "2023-06-01",
    });

    // è½¬æ¢æ¶ˆæ¯æ ¼å¼
    const systemMessage = messages.find((m) => m.role === "system");
    const chatMessages = messages.filter((m) => m.role !== "system");

    const payload = {
      model: model || AI_SERVICES.anthropic.defaultModel,
      max_tokens: 2000,
      messages: chatMessages,
      stream,
      ...otherParams,
    };

    if (systemMessage) {
      payload.system = systemMessage.content;
    }

    if (stream) {
      const response = await axiosInstance.post("/v1/messages", payload, {
        responseType: "stream",
      });

      res.setHeader("Content-Type", "text/event-stream");
      res.setHeader("Cache-Control", "no-cache");
      res.setHeader("Connection", "keep-alive");

      response.data.pipe(res);
    } else {
      const response = await axiosInstance.post("/v1/messages", payload);
      res.json(response.data);
    }
  } catch (error) {
    console.error("Claude APIé”™è¯¯:", error.response?.data || error.message);
    res.status(error.response?.status || 500).json({
      error:
        error.response?.data?.error?.message ||
        error.message ||
        "Claude APIè°ƒç”¨å¤±è´¥",
    });
  }
});

// ============= é€šä¹‰åƒé—®å¤„ç† =============
app.post("/api/qwen/chat", async (req, res) => {
  try {
    const { messages, model, stream = true, apiKey, ...otherParams } = req.body;

    if (!apiKey) {
      return res.status(400).json({ error: "APIå¯†é’¥æœªæä¾›" });
    }

    const axiosInstance = createAxiosInstance(AI_SERVICES.qwen.baseURL, {
      Authorization: `Bearer ${apiKey}`,
      "X-DashScope-SSE": "enable",
    });

    const payload = {
      model: model || AI_SERVICES.qwen.defaultModel,
      input: { messages },
      parameters: {
        temperature: 0.7,
        max_tokens: 2000,
        incremental_output: stream,
        ...otherParams,
      },
    };

    if (stream) {
      const response = await axiosInstance.post(
        "/services/aigc/text-generation/generation",
        payload,
        {
          responseType: "stream",
        }
      );

      res.setHeader("Content-Type", "text/event-stream");
      res.setHeader("Cache-Control", "no-cache");
      res.setHeader("Connection", "keep-alive");

      response.data.pipe(res);
    } else {
      const response = await axiosInstance.post(
        "/services/aigc/text-generation/generation",
        payload
      );
      res.json(response.data);
    }
  } catch (error) {
    console.error("é€šä¹‰åƒé—®é”™è¯¯:", error.response?.data || error.message);
    res.status(error.response?.status || 500).json({
      error:
        error.response?.data?.error?.message ||
        error.message ||
        "é€šä¹‰åƒé—®è°ƒç”¨å¤±è´¥",
    });
  }
});

// ============= Google Geminiå¤„ç† =============
app.post("/api/gemini/chat", async (req, res) => {
  try {
    const { messages, model, stream = true, apiKey, ...otherParams } = req.body;

    if (!apiKey) {
      return res.status(400).json({ error: "APIå¯†é’¥æœªæä¾›" });
    }

    const modelName = model || AI_SERVICES.gemini.defaultModel;
    const endpoint = stream
      ? `/models/${modelName}:streamGenerateContent?key=${apiKey}`
      : `/models/${modelName}:generateContent?key=${apiKey}`;

    const axiosInstance = createAxiosInstance(AI_SERVICES.gemini.baseURL);

    // è½¬æ¢æ¶ˆæ¯æ ¼å¼
    const systemMessage = messages.find((m) => m.role === "system");
    const chatMessages = messages.filter((m) => m.role !== "system");

    const payload = {
      contents: chatMessages.map((msg) => ({
        role: msg.role === "assistant" ? "model" : "user",
        parts: [{ text: msg.content }],
      })),
      generationConfig: {
        temperature: 0.7,
        maxOutputTokens: 2000,
        ...otherParams,
      },
    };

    if (systemMessage) {
      payload.systemInstruction = {
        parts: [{ text: systemMessage.content }],
      };
    }

    if (stream) {
      const response = await axiosInstance.post(endpoint, payload, {
        responseType: "stream",
      });

      res.setHeader("Content-Type", "text/event-stream");
      res.setHeader("Cache-Control", "no-cache");
      res.setHeader("Connection", "keep-alive");

      response.data.pipe(res);
    } else {
      const response = await axiosInstance.post(endpoint, payload);
      res.json(response.data);
    }
  } catch (error) {
    console.error("Gemini APIé”™è¯¯:", error.response?.data || error.message);
    res.status(error.response?.status || 500).json({
      error:
        error.response?.data?.error?.message ||
        error.message ||
        "Gemini APIè°ƒç”¨å¤±è´¥",
    });
  }
});

// ============= é…ç½®æµ‹è¯• (å¢å¼ºç‰ˆ) =============
app.post("/api/test", async (req, res) => {
  console.log("æ”¶åˆ°APIæµ‹è¯•è¯·æ±‚");

  try {
    const { provider, apiKey } = req.body;

    if (!provider || !apiKey) {
      return res.status(400).json({ error: "ç¼ºå°‘å¿…è¦å‚æ•°" });
    }

    console.log(`æµ‹è¯•${provider}è¿æ¥...`);

    let testResult = false;
    let errorMessage = "";

    switch (provider) {
      case "openai":
        try {
          const axiosInstance = createAxiosInstance(
            AI_SERVICES.openai.baseURL,
            {
              Authorization: `Bearer ${apiKey}`,
            }
          );
          await axiosInstance.get("/models", { timeout: 10000 });
          testResult = true;
        } catch (error) {
          errorMessage = error.response?.data?.error?.message || error.message;
          console.log("OpenAIæµ‹è¯•å¤±è´¥:", errorMessage);
        }
        break;

      case "zhipu":
        try {
          const axiosInstance = createAxiosInstance(AI_SERVICES.zhipu.baseURL, {
            Authorization: `Bearer ${apiKey}`,
          });
          await axiosInstance.post(
            "/chat/completions",
            {
              model: "glm-4",
              messages: [{ role: "user", content: "hi" }],
              max_tokens: 10,
              stream: false,
            },
            { timeout: 10000 }
          );
          testResult = true;
        } catch (error) {
          errorMessage = error.response?.data?.error?.message || error.message;
          console.log("æ™ºè°±AIæµ‹è¯•å¤±è´¥:", errorMessage);
        }
        break;

      default:
        errorMessage = "ä¸æ”¯æŒçš„æœåŠ¡å•†";
    }

    if (testResult) {
      console.log(`${provider} APIæµ‹è¯•æˆåŠŸ`);
      res.json({ success: true, message: "APIè¿æ¥æµ‹è¯•æˆåŠŸ" });
    } else {
      console.log(`${provider} APIæµ‹è¯•å¤±è´¥:`, errorMessage);
      res.status(400).json({ success: false, message: errorMessage });
    }
  } catch (error) {
    console.error("æµ‹è¯•è¿‡ç¨‹å‡ºé”™:", error);
    res.status(500).json({ success: false, message: error.message });
  }
});

// å…¨å±€é”™è¯¯å¤„ç†ä¸­é—´ä»¶
app.use((error, req, res, next) => {
  console.error("æœåŠ¡å™¨é”™è¯¯:", error);
  if (!res.headersSent) {
    res.status(500).json({ error: "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯", details: error.message });
  }
});

// 404å¤„ç†
app.use("*", (req, res) => {
  console.log(`404 - æœªæ‰¾åˆ°è·¯å¾„: ${req.method} ${req.originalUrl}`);
  res.status(404).json({
    error: "æ¥å£ä¸å­˜åœ¨",
    path: req.originalUrl,
    method: req.method,
    availableEndpoints: [
      "/api/health",
      "/api/openai/chat",
      "/api/zhipu/chat",
      "/api/anthropic/chat",
      "/api/qwen/chat",
      "/api/gemini/chat",
      "/api/test",
    ],
  });
});

// å¯åŠ¨æœåŠ¡å™¨
const server = app.listen(PORT, "0.0.0.0", () => {
  console.log("=================================");
  console.log(`ğŸš€ åç«¯æœåŠ¡å™¨è¿è¡ŒæˆåŠŸï¼`);
  console.log(`ğŸ“¡ æœåŠ¡åœ°å€: http://localhost:${PORT}`);
  console.log(
    `ğŸ“¡ å‰ç«¯åœ°å€: ${process.env.FRONTEND_URL || "http://localhost:3000"}`
  );
  console.log(`ğŸŒ ä»£ç†çŠ¶æ€: ${PROXY_URL ? `å·²å¯ç”¨ (${PROXY_URL})` : "æœªå¯ç”¨"}`);
  console.log(`ğŸ”— å¥åº·æ£€æŸ¥: http://localhost:${PORT}/api/health`);
  console.log(`ğŸ“‹ å¯ç”¨æœåŠ¡: ${Object.keys(AI_SERVICES).join(", ")}`);
  console.log("=================================");
});

// ä¼˜é›…å…³é—­
process.on("SIGTERM", () => {
  console.log("æ”¶åˆ°SIGTERMä¿¡å·ï¼Œæ­£åœ¨ä¼˜é›…å…³é—­æœåŠ¡å™¨...");
  server.close(() => {
    console.log("æœåŠ¡å™¨å·²å…³é—­");
    process.exit(0);
  });
});

module.exports = app;
